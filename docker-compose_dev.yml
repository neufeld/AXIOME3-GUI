version: "3.5"
services:
  nginx:
    image: nginx:1.19.1-alpine
    ports:
      - '8080:80'
    volumes:
      - ./nginx/dev/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - frontend
      - backend
    restart: on-failure

  rabbit:
    image: rabbitmq:3.8.5-management
    ports:
      - 15673:15672 # in case user has rabbitMQ installed on host
      - 5673:5672
    environment:
      - RABBITMQ_DEFAULT_USER=axiome3
      - RABBITMQ_DEFAULT_PASS=neufeld
      - RABBITMQ_DEFAULT_VHOST=axiome3_host

  flower:
    build:
      context: ./flower
      dockerfile: Dockerfile
    command: "/flower/wait-for-it.sh rabbit:5672 -- celery --broker=amqp://axiome3:neufeld@rabbit:5672/axiome3_host flower --broker_api=http://axiome3:neufeld@rabbit:15672/api/axiome3_host --port=5555"
    ports:
      - 5555:5555
    restart: on-failure
    volumes:
      - ./flower:/flower

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        - QIIME2_RELEASE=2020.6
        - CLASSIFIER_GDRIVE_ID=12jug9XZcbUefevtTnENGudjGqaAL0LCo
    command: ["python", "dev_server.py", '--py-autoreload', '1'] #["flask", "run", "--host", "0.0.0.0"]
    volumes:
      - ./backend:/backend
      - /:/hostfs:ro # Assumes host root is '/'
      - ./output:/output # Stores all the output to this directory
      - ./log:/log # For logging
      - input:/input # Named volume
      - ./pipeline:/pipeline
    ports:
      - '5000'
    environment:
      - FLASK_ENV=development
      - FLASK_APP=AXIOME3_app/app
      - PYTHONPATH=/pipeline # Add AXIOME3 pipeline to PYTHONPATH
      - LUIGI_CONFIG_PATH=/pipeline/configuration/luigi.cfg
      - GMAIL_SENDER=axiome333@gmail.com

  pipeline_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        - QIIME2_RELEASE=2020.6
        - CLASSIFIER_GDRIVE_ID=12jug9XZcbUefevtTnENGudjGqaAL0LCo
    command: "celery -A AXIOME3_app.celery_app:app worker --concurrency=1 -n worker1@%h -Q pipeline --loglevel=INFO"
    volumes:
      - /:/hostfs:ro # Assumes host root is '/'
      - ./backend:/backend
      - ./output:/output # Stores all the output to this directory
      - ./log:/log # For logging
      - input:/input # Named volume
      - ./pipeline:/pipeline
    environment:
      - PYTHONPATH=/pipeline # Add AXIOME3 pipeline to PYTHONPATH
      - LUIGI_CONFIG_PATH=/pipeline/configuration/luigi.cfg
      - GMAIL_SENDER=axiome333@gmail.com

  extension_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        - QIIME2_RELEASE=2020.6
        - CLASSIFIER_GDRIVE_ID=12jug9XZcbUefevtTnENGudjGqaAL0LCo
    command: "celery -A AXIOME3_app.celery_app:app worker --concurrency=1 -n worker2@%h -Q extension --loglevel=INFO"
    volumes:
      - /:/hostfs:ro # Assumes host root is '/'
      - ./backend:/backend
      - ./output:/output # Stores all the output to this directory
      - ./log:/log # For logging
      - input:/input # Named volume
      - ./pipeline:/pipeline
    environment:
      - PYTHONPATH=/pipeline # Add AXIOME3 pipeline to PYTHONPATH

  frontend:
    build:
      context: ./frontend
      dockerfile: dev.Dockerfile
    command: ["npm", "start"]
    volumes:
      - ./frontend:/frontend
      - node_module:/frontend/node_modules
    ports:
      - '3000'
    environment:
      - NODE_ENV=development
      - HOST=0.0.0.0
      - CHOKIDAR_USEPOLLING=true
      - REACT_APP_QIIME2_RELEASE=2020.6
      - REACT_APP_SILVA_VERSION=138
    links:
      - backend
    tty: true
volumes:
  input:
  node_module: